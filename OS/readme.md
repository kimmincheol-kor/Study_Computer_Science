# Operating System

<br>

## Program, Process, Thread란?

### 프로그램 (Program)

- 어떤 작업을 위해 `실행할 수 있는 파일`

### 프로세스 (Process)

- 컴퓨터에서 연속적으로 `실행되고 있는 프로그램` == `실행된 프로그램`
- 디스크에로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 프로그램의 인스턴스 (독릭적인 개체)
- 운영체제로부터 자원을 할당받는 `작업의 단위`
- 프로세스별로 PCB라는 운영체제에서 프로세스에 대한 정보를 저장한 자료구조를 가진다.

<br>

> ***PCB 에 저장되는 정보***   
>    
> 프로세스 식별자(Process ID, PID) : 프로세스 식별번호   
> 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장   
> 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소   
> CPU 레지스터   
> CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등   
> 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함   
> 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록   
> 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등   

<br>

- 프로세스 별로 독립된 메모리 영역(Code, Data, Stack, Heap)을 가진다. (운영체제로부터 할당)
- 한 프로세스는 다른 프로세스의 영역에 접근할 수 없다. -> 접근하려면 `프로세스 간 통신(IPC)`를 사용
- 기본적으로 프로세스당 최소 1개의 스레드를 가진다.

### 스레드 (Thread)

- 프로세스 내에서 실행되는 여러 `흐름의 단위`
- 프로세스가 할당받은 자원을 이용하는 `독립적인 실행의 단위`

- 각 스레드는 프로세스 내에서 Stack, PC 레지스터만 독립적으로 할당받으며 Code, Data, Heap 영역은 공유한다.
- 같은 프로세스 내의 스레드들은 힙 공간의 데이터를 공유할 수 있다.
- 한 스레드가 프로세스 자원을 변경하면 다른 스레드도 변경 결과를 즉시 확인할 수 있다.

- 멀티 프로세스보다 멀티 스레드가 자원 할당, 통신, CPU 점유 전환에서 효율적이다.
- 단, 힙 영역을 공유하는 과정에서 동기화 문제가 발생할 수 있다.


<br>


## 스케줄러

### 프로세스를 스케줄링하는 Queue

- `Job Queue` : 현재 시스템 내에 있는 모든 프로세스의 집합
- `Ready Queue` : 현재 메모리에 적재되어 CPU 할당을 기다리는 프로세스의 집합
- `Device Queue` : Device I/O 작업을 위해 대기하고 있는 프로세스의 집합

### 스케줄링 Queue에 입출력하는 스케줄러

- `장기스케줄러`(Long-term scheduler or job scheduler)
> 메모리 - 디스크 사이의 스케줄링 담당.   
> 스케줄링 알고리즘에 따라 디스크 내의 프로그램을 `어떤 순서로 메모리에 적재`할지 결정.   
> 디스크같은 저장장치에 프로그램을 저장해놓고, 필요할 때 실행할 작업을 Ready Queue에 적재한다.   
> 이때 프로세스는 New -> Ready 상태로 전이를 승인(Admit) 받기 때문에 Admit Scheduler라고도 한다.   

- `단기스케줄러`(Short-term scheduler or CPU scheduler)
> CPU - 메모리 사이의 스케줄링 담당.   
> Ready Queue 존재하는 프로세스 중 `어떤 프로세스를 실행`할지 결정   
> 이때 프로세스는 Ready -> Running -> Waiting or Ready 상태로 전이된다.   

- `중기스케줄러`(Medium-term scheduler or Swapper)
> 메모리 - 디스크 사이에서 메모리 과부하를 관리하는 스케줄러.   
> 프로세스를 메모리에서 디스크로 쫓아낸다. (Swapping)   
> 이때 프로세스는 Ready -> Suspended -> Ready 로 전이된다.   

### CPU 스케줄링 방식

#### FCFS (First Come, First Served)
- **특징**
1. 먼저 온 순서대로 처리.
2. 비선점형(Non-Preemptive) 스케줄링 방식

- **문제점**
1. Convoy Effect : 소요시간이 긴 프로세스로 인해 효율성이 낮아지는 현상

#### SJF (Shortest Job First)
- **특징**
1. 소요 시간(CPU Burst time)이 잛은 프로세스 먼저 처리
2. 비선점형 스케줄링 방식

- **문제점**
1. starvation : 효율성을 추구하지만 특정 프로세스는 영원히 처리되지 못하는 현상

#### SRT (Shortest Remaining time First)
- **특징**
1. 새로운 프로세스가 도착할때마다 새로 스케줄링 : 남은 Burst Time이 가장 짧은 프로세스 우선
2. 선점형(Preemptive) 스케줄링 방식 : 프로세스로부터 CPU 할당을 뺏는다

- **문제점**
1. starvation
2. CPU 사용시간을 측정할 수 없다.

#### Priority Scheduling
- **특징**
1. 프로세스별 우선 순위를 할당하여 우선 순위가 높은 프로세스 우선적으로 처리
2. 선점형, 비선점형 모두 적용 가능

- **문제점**
1. starvation
2. Indefinite Blocking : 실행 준비는 되었으나 CPU를 사용하지 못하는 프로세스를 무기한 대기하는 상태.

- *해결법**
1. Aging : 우선순위가 낮은 프로세스가 오래 대기할수록 우선순위가 높아지는 방식.

#### RR (Round Robin)
- **특징**
1. 현대적인 스케줄링 방식
2. 모든 프로세스가 동일한 크기의 CPU 사용 시간을 할당 받는다.
3. 할당 시간이 지나면 선점당하여 가장 뒤에서 대기한다.
4. CPU Burst Time이 랜덤한 프로세스들이 섞여있을때 가장 효율적

- **장점**
1. Response Time이 빨라진다. 모든 프로세스가 정해진 응답 시간 이하의 시간으로 응답을 받을 수 있다.

- **주의점**
1. 할당하는 Time Quantum이 커지면 FCFS와 비슷해지며 너무 작아지면 잦은 Context Switch로 인해 OverHead가 커진다.


<br>


## 프로세스 동기화

#### 동기와 비동기의 차이 (Sync vs. Async)

- 일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우를 동기 라고 표현하고 그렇지 않은 경우에 대해서 비동기 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking되어 있다는 것을 의미한다. 비동기의 경우, blocking되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task 를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

#### Critical Section (임계 구역)

- 멀티 스레딩 시스템에서 동일한 자원에 `동시에 접근할 수 있는 작업을 실행하는 코드 영역`을 `임계 영역`이라고한다.
- 임계 구역에 동시에 접근하여 데이터를 수정할 경우 충돌이 발생할 수 있다.
- 이를 해결하기 위해서는 동기화 기법으로 제어해야 한다.

#### 동기화 기법

- 스레드 동기화 방법
1. 실행 순서의 동기화 : 실행 순서를 정의하고 따르도록 한다.
2. 메모리 접근에 대한 동기화 : 한 순간에 하나의 스레드만 접근하게 한다.

- 동기화 기법의 종류
1. 유저 모드 동기화 : 성능상 이점이 있으나 기능상의 제한이 있다. (InterLock ...)
2. 커널 모드 동기화 : 성능 저하가 생긴다. (Mutex, Semaphore, Event ...)

- `Mutex`
상호 배제라고 하며, 뮤텍스 객체는 둘 이상의 스레드가 동시에 사용할 수 없다.   
Lock을 소유한 프로세스가 해제할 떄까지 유지된다.   

- `Semaphore` (Counting/Binary Semaphore)
공유된 자원을 여러 프로세스가 접근하는 것을 막는것   
Semaphore를 소유하지 않은 스레드가 해제할 수 있다.   

#### Deadlock (데드락, 교착 상태)

- 데드락은 모든 스레드가 임계 구역에 접근하기 위해 대기하는 상태에 빠짐으로써 `무한 대기 상태`에 빠지는 상태이다.
- 방지하기 위해서는 대기 상태의 싸이클이 존재하지 않도록 설계하여야 한다.


<br>


## 메모리 관리

- 각각의 프로세스 는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.

#### Swapping

- 메모리의 관리를 위해 사용되는 기법
- 주기억장치(메모리) - 보조기억장치(디스크) 사이에서 프로세르를 Swap-in, Swap-out한다.

#### Fragmentation (단편화)

- 프로세스들이 메모리에 적재되고, 해제되는 과정이 반복되면서 메모리 공간에 사용하지 못할 크기의 공간들이 생겨나는 현상.
1. 외부 단편화 : 남은 메모리 공간은 충분하지만 분산되어있어 할당할 수 없는 상황.
2. 내부 단편화 : 프로세스가 필요한 메모리 양보다 많이 할당되어서 낭비되는 상황.

#### Paging (페이징)

- 메모리 공간이 연속적이어야한다는 제약을 없애는 관리 기법. (Page Mapping)
- 물리 메모리를 고정 크기(Frame)로 분리되고, 각각의 블록을 Page라고 하고, Page단위로 할당한다.
- Page의 크기가 너무 작으면 Page Mapping 과정이 많아지므로 효율이 떨어진다.
- Page의 크기가 너무 크면 내부 단편화 문제의 비중이 늘어난다. 필요 이상의 메모리를 할당한다.

#### Segmentation

- Paging과는 다르게 서로 크기가 다른 단위인 Segment로 분할하여 필요한 만큼만 메모리를 할당한다.
- 내부 단편화 문제는 해결되지만 외부 단편화 문제는 생겨난다.


<br>


## 가상 메모리

- 다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다. 가상메모리는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법 이며, 프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다.

#### 가상 메모리 개발 배경

- 메모리 용량의 한계로 인해 다중 프로그래밍에 제약이 많았다.
- Swapping에 필요한 데이터의 크기가 줄어들기 때문에 빠르게 실행된다.
- 실제로 동작하는 코드만 물리 메모리에 적재하고, 동작하지 않는 코드는 가상 메모리(보조기억장치)에 대기시킨다.
- 프로세스간 메모리를 공유하는 것은 불가능하지만, 가상 메모리에서는 가능하다.
- 페이지로 관리된다. 실제 필요한 페이지들만 메모리 적재, 사용되지 않을 페이지는 디스크에 대기. => Demand Paging

#### Page Fault (페이지 부재)

- 필요한 페이지가 메모리에 적재되어 있지 않은 현상을 페이지 부재라고 한다.
- 이때 필요한 페이지를 메모리에 적재하는 과정에서 메모리에 빈 공간이 없다면, `페이지 교체`가 이루어져야 한다.

- 페이지 교체 방법
> 1. 디스크에서 필요한 페이지의 위치를 찾는다
> 2. 빈 페이지 프레임을 찾는다.   
> > `페이지 교체 알고리즘`을 통해 희생될(victim) 페이지를 고른다.   
> > 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.   
> 3. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
> 4. 사용자 프로세스 재시작

- 페이지 교체 알고리즘
> 1. FIFO
> > 먼저 적재된 순서대로 해제시키는 알고리즘   
> > 자주 사용되는 페이지를 해제하여 부재율을 높이는 부작용을 초래한다.   
> > Belady의 모순 : 페이지를 저장할 수 있는 공간을 늘려도 오히려 부재율이 더 높아지는 모순이 존재한다.   

> 2. Optiaml (OPT)
> > 가장 오랫동안 사용되지 않을 페이지를 찾아서 교체하는 알고리즘   
> > 가장 낮은 페이지 부재율을 보장한다. (이상적이다.)   
> > 구현의 어려움이 있다. (메모리 사용 계획을 파악할 수가 없다.)   

> 3. LRU (Least Recently Used)
> > 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘   
> > 가장 쉽게 OPT 알고리즘에 근사한다.   

> 4. LFU (Least Frequently Used)
> > 사용 횟수가 가장 적은 페이지를 교체하는 알고리즘   
> > 많이 사용하다가, 사용하지 않게 된 페이지가 계속 메모리에 머물 수 있다. => 잘 사용되지 않는 알고리즘이다.   

> 5. MFU (Most Frequently Used)
> > 가장 사용 횟수가 적은 페이지가 앞으로 많이 사용될 것이라는 가정에 기반한 알고리즘이다.   
> > 잘 사용되지 않는다.   


<br>


## 캐시

- 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리이다. 이러한 역할을 수행하기 위해서는 CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다. 캐시의 성능은 작은 용량의 캐시 메모리에 CPU 가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.
- CPU가 원하는 데이터가 캐시에 존재할 확률인 `적중율 (Hit Rate)`이 곧 캐시의 성능이다.

- 이때 적중률을 극대화 시키기 위해 `지역성의 원리`를 사용한다. 기억 장치내 데이터를 균일하게 접근하는 것이 아닌 특정 부분을 집중적으로 참조하는 특성이다.
> 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.   
> 공간 지역성 : 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성   





<br>
